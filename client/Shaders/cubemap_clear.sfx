//  Copyright (c) 2015-2017 Simul Software Ltd. All rights reserved.
#include "shader_platform.sl"
#include "common.sl"
#include "video_types.sl"
#include "render_states.sl"
#include "sampler_states.sl"
#include "camera_constants.sl"
#include "quaternion.sl"
#include "cubemap_constants.sl"
#include "random.sl"

uniform TextureCube cubemapTexture;
uniform Texture2D<vec4> perspectiveTexture; 
uniform Texture2D<vec4> plainTexture; 
uniform RWStructuredBuffer<uint4> RWTagDataIDBuffer;
uniform StructuredBuffer<uint4> TagDataIDBuffer;
uniform RWTexture2DArray<uchar4> RWTextureTargetArray;
uniform RWTexture2D<vec4> RWTextureTarget;
uniform StructuredBuffer<VideoTagDataCube> TagDataCubeBuffer;
 
vec2 OffsetScale(vec2 uv, vec4 offsc)
{
	return uv * offsc.zw + offsc.xy;
}

vec2 ViewToServerScreenSpace(vec3 pos)
{
	vec4 clip_pos = vec4(pos, 1.0);
	clip_pos = mul(serverProj, clip_pos);

	pos = clip_pos.xyz;

	// Move to NDC space
	if (clip_pos.w != 0)
	{
		pos /= clip_pos.w;
	}

	// Finally, convert to uv
	return 0.5 * (vec2(1.0, 1.0) + vec2(pos.x,-pos.y));
}

uint UVWToFaceIndex(float3 view)
{
	float maxDirection = max(abs(view.x), max(abs(view.y), abs(view.z)));
	uint faceIndex = 0;
	if (maxDirection == abs(view.x))
		faceIndex = 0;
	else if (maxDirection == abs(view.y))
		faceIndex = 2;
	else if (maxDirection == abs(view.z))
		faceIndex = 4;

	if (faceIndex == 0 && maxDirection == -view.x)
		faceIndex++;
	else if (faceIndex == 2 && maxDirection == -view.y)
		faceIndex++;
	else if (faceIndex == 4 && maxDirection == -view.z)
		faceIndex++;

	return faceIndex;
}

vec4 CubemapFaceColour(uint faceIndex)
{
	vec4 result = vec4(0.0, 0.0, 0.0, 1.0);

	switch (faceIndex)
	{
		case 0:
			result = vec4(1.0, 0.0, 0.0, 1.0);
			break;
		case 1:
			result = vec4(0.0, 1.0, 1.0, 1.0);
			break;
		case 2:
			result = vec4(0.0, 1.0, 0.0, 1.0);
			break;
		case 3:
			result = vec4(1.0, 0.0, 1.0, 1.0);
			break;
		case 4:
			result = vec4(0.0, 0.0, 1.0, 1.0);
			break;
		case 5:
			result = vec4(1.0, 1.0, 0.0, 1.0);
			break;
	}

	return result;
}

shader vec4 PS_NormalView(posTexVertexOutput IN) : SV_TARGET
{
	const float PI = 3.1415926536;
	const float TwoPI = 2.0 * PI;
	vec3 view	= -TexCoordsToView(IN.texCoords);
	float phi	= atan2(-view.x, -view.y) / TwoPI;
	float theta	= acos(-view.z) / PI;
	vec2  uv	= fract(vec2(phi, theta));
	
	vec4 lookup = plainTexture.SampleLevel(wrapSamplerState, OffsetScale(uv, depthOffsetScale), 0).rgba;
	vec4 depth_lookup = plainTexture.SampleLevel(wrapSamplerState, OffsetScale(uv, depthOffsetScale), 0).rgba;
	
	return lookup*depth_lookup;
}

shader vec4 PS_UseCubemap(posTexVertexOutput IN) : SV_TARGET
{
	const float PI = 3.1415926536;
	const float TwoPI = 2.0 * PI;
	vec3 view_orig = TexCoordsToView(IN.texCoords);
	//view_orig.xy = -view_orig.xy;
	//view_orig.z *= -1.0;
	int id = int(TagDataIDBuffer[0].x);
	VideoTagDataCube tagData = TagDataCubeBuffer[id];
	vec3 offsetFromVideo2 = cameraPosition - tagData.cameraPosition;
	vec4 lookup = cubemapTexture.SampleLevel(cubeSamplerState, view_orig, 0.0);
	vec3 view = view_orig;
	float dist_m=0.0;
	for (int i = 0; i < 5; i++)
	{
		float depth = lookup.a;
		dist_m = 5.0 + 25.0 * depth;
		vec3 pos_m = dist_m * view_orig;
		pos_m += vec3(offsetFromVideo2.yxz) * step(-0.999, -depth);

		// But this does not intersect at depth. We want the vector from the original centre, of 
		// original radius to hit point
		float R = dist_m;
		float F = length(offsetFromVideo2);
		if (F > 0)
		{
			float D = -dot(normalize(offsetFromVideo2), view_orig);
			float b = F * D;
			float c = F * F - R * R;
			float U = -b + sqrt(b * b - c);
			pos_m += (U - R) * view_orig;

			view = normalize(pos_m);
			lookup = cubemapTexture.SampleLevel(cubeSamplerState, view, 0).rgba;
		}
	}
	lookup.rgb += vec3(0.005, 0.005, 0.005);
	//lookup.rgb += abs(tagData.cameraPosition);
	lookup = cubemapTexture.SampleLevel(cubeSamplerState, view_orig, 0.0);
	return lookup;
}

shader vec4 PS_FarCubemap(posTexVertexOutput IN) : SV_TARGET
{
	const float PI = 3.1415926536;
	const float TwoPI = 2.0 * PI;
	vec3 view = TexCoordsToView(IN.texCoords);
	vec4 lookup = cubemapTexture.SampleLevel(cubeSamplerState, view, 0.0);
	//lookup.xyz += view.xyz;
	return lookup;
}

shader vec4 PS_FarPerspective(posTexVertexOutput IN) : SV_TARGET
{
	vec3 view_orig = -TexCoordsToView(IN.texCoords).xzy; // TODO: Remove swizzle
	view_orig.xz *= -1.0;
	view_orig = normalize(rotate_by_quaternion(cameraRotation, view_orig));
	view_orig.xy *= -1.0;
	vec2 uv = ViewToServerScreenSpace(view_orig);
	vec4 lookup = perspectiveTexture.SampleLevel(wrapSamplerState, uv, 0);
	return lookup;
}
shader vec4 PS_FarCubemap_MV(posTexVertexOutput IN, uint viewID
							 : SV_ViewID) : SV_TARGET
{
	const float PI = 3.1415926536;
	const float TwoPI = 2.0 * PI;
	vec3 view_orig = -TexCoordsToView(IN.texCoords, viewID);
	view_orig.xy = -view_orig.xy;
	view_orig.z *= -1.0;
	vec4 lookup = cubemapTexture.SampleLevel(cubeSamplerState, view_orig, 0.0);
	return lookup;
}

shader vec4 PS_FarPerspective_MV(posTexVertexOutput IN, uint viewID
								 : SV_ViewID) : SV_TARGET
{
	vec3 view_orig = -TexCoordsToView(IN.texCoords, viewID).xzy; // TODO: Remove swizzle
	// Negate because rotations are set up for forward y
	view_orig.xz *= -1.0;
	// Transform to world space
	view_orig = normalize(rotate_by_quaternion(cameraRotation, view_orig));
	view_orig.xy *= -1.0;
	vec2 uv = ViewToServerScreenSpace(view_orig);
	vec4 lookup = perspectiveTexture.SampleLevel(wrapSamplerState, uv, 0);
	return lookup;
}

shader vec4 PS_UsePerspective(posTexVertexOutput IN) : SV_TARGET
{
	int id = int(TagDataIDBuffer[0].x);
	VideoTagDataCube tagData = TagDataCubeBuffer[id];

	// Transform to view space
	// Swizzle y and z to go from left-handed (HLSL) to engineering
	// because rotations are in engineering coordinate system.
	vec3 view_orig = -TexCoordsToView(IN.texCoords).xzy; //TODO: Remove swizzle

	// Negate because rotations are set up for forward y
	view_orig.xz *= -1.0;

	// Transform to world space
	view_orig = normalize(rotate_by_quaternion(cameraRotation, view_orig));

	// Transform to server camera space
	view_orig = normalize(rotate_by_quaternion(quat_inverse(tagData.cameraRotation), view_orig)).xzy;

	view_orig.xy *= -1.0;

	vec2 uv = ViewToServerScreenSpace(view_orig);
	
	vec3 offsetFromVideo = cameraPosition - tagData.cameraPosition;

	// Transform to server camera space. Saves on a rotation each iteration of the loop
	offsetFromVideo = rotate_by_quaternion(quat_inverse(tagData.cameraRotation), offsetFromVideo).xzy;

	offsetFromVideo.xy *= -1.0;

	vec4 lookup = perspectiveTexture.SampleLevel(wrapSamplerState, uv, 0);

	float F = length(offsetFromVideo);
	if (F <= 0)
	{
		return lookup;
	}

	vec3 view = view_orig;
	float dist_m=0.0;
	for (int i = 0; i < 5; i++)
	{
		float depth = lookup.a;
		dist_m = 5.0 + 25.0 * depth;
		vec3 pos_m = dist_m * view_orig;
		pos_m += offsetFromVideo * step(-0.999, -depth);

		// original radius to hit point
		float R = dist_m;
	
		float D = -dot(normalize(offsetFromVideo), view_orig);
		float b = F * D;
		float c = F * F - R * R;
		float U = -b + sqrt(b * b - c);
		pos_m += (U - R) * view_orig;

		view = normalize(pos_m);

		uv = ViewToServerScreenSpace(view);
		lookup = perspectiveTexture.SampleLevel(wrapSamplerState, uv, 0);
	}
	return lookup;
}

shader vec4 PS_UseCubemap_MV(posTexVertexOutput IN, uint viewID : SV_ViewID) : SV_TARGET
{
	const float PI = 3.1415926536;
	const float TwoPI = 2.0 * PI;
	vec3 view_orig = -TexCoordsToView(IN.texCoords, viewID);
	view_orig.xy = -view_orig.xy;
	view_orig.z *= -1.0;
	int id = int(TagDataIDBuffer[0].x);
	VideoTagDataCube tagData = TagDataCubeBuffer[id];
	vec3 offsetFromVideo2 = cameraPosition - tagData.cameraPosition;
	vec4 lookup = cubemapTexture.SampleLevel(cubeSamplerState, view_orig, 0.0);
	vec3 view = view_orig;
	float dist_m=0.0;
	for (int i = 0; i < 5; i++)
	{
		float depth = lookup.a;
		dist_m = 5.0+25.0 * depth;
		vec3 pos_m = dist_m * view_orig;
		pos_m += vec3(offsetFromVideo2.yxz)*step(-0.999, -depth);

		// But this does not intersect at depth. We want the vector from the original centre, of 
		// original radius to hit point
		float R = dist_m;
		float F = length(offsetFromVideo2);
		if (F > 0)
		{
			float D = -dot(normalize(offsetFromVideo2), view_orig);
			float b = F * D;
			float c = F * F - R * R;
			float U = -b + sqrt(b * b - c);
			pos_m += (U - R) * view_orig;

			view = normalize(pos_m);
			lookup = cubemapTexture.SampleLevel(cubeSamplerState, view, 0).rgba;
		}
	}
	return lookup;
}
shader vec4 PS_UsePerspective_MV(posTexVertexOutput IN, uint viewID : SV_ViewID) : SV_TARGET
{
	int id = int(TagDataIDBuffer[0].x);
	VideoTagDataCube tagData = TagDataCubeBuffer[id];

	// Transform to view space
	// Swizzle y and z to go from left-handed (HLSL) to engineering
	// because rotations are in engineering coordinate system.
	vec3 view_orig = -TexCoordsToView(IN.texCoords, viewID).xzy; //TODO: Remove swizzle

	// Negate because rotations are set up for forward y
	view_orig.xz *= -1.0;

	// Transform to world space
	view_orig = normalize(rotate_by_quaternion(cameraRotation, view_orig));

	// Transform to server camera space
	view_orig = normalize(rotate_by_quaternion(quat_inverse(tagData.cameraRotation), view_orig)).xzy;

	view_orig.xy *= -1.0;

	vec2 uv = ViewToServerScreenSpace(view_orig);
	
	vec3 offsetFromVideo = cameraPosition - tagData.cameraPosition;

	// Transform to server camera space. Saves on a rotation each iteration of the loop
	offsetFromVideo = rotate_by_quaternion(quat_inverse(tagData.cameraRotation), offsetFromVideo).xzy;

	offsetFromVideo.xy *= -1.0;

	vec4 lookup = perspectiveTexture.SampleLevel(wrapSamplerState, uv, 0);

	float F = length(offsetFromVideo);
	if (F <= 0)
	{
		return lookup;
	}

	vec3 view = view_orig;
	float dist_m=0.0;
	for (int i = 0; i < 5; i++)
	{
		float depth = lookup.a;
		dist_m = 5.0 + 25.0 * depth;
		vec3 pos_m = dist_m * view_orig;
		pos_m += offsetFromVideo * step(-0.999, -depth);

		// original radius to hit point
		float R = dist_m;
	
		float D = -dot(normalize(offsetFromVideo), view_orig);
		float b = F * D;
		float c = F * F - R * R;
		float U = -b + sqrt(b * b - c);
		pos_m += (U - R) * view_orig;

		view = normalize(pos_m);

		uv = ViewToServerScreenSpace(view);
		lookup = perspectiveTexture.SampleLevel(wrapSamplerState, uv, 0);
	}
	return lookup;
}
            // grid function from Best Darn Grid article
float PristineGrid(vec2 uv, float lineWidth)
{
    vec4 uvDDXY = vec4(ddx(uv), ddy(uv));
    vec2 uvDeriv = vec2(length(uvDDXY.xz), length(uvDDXY.yw));
	vec2 W=vec2(lineWidth,lineWidth);
    vec2 drawWidth = clamp(W, uvDeriv,vec2(0.5,0.5));
    vec2 lineAA = max(uvDeriv, 0.000001) * 1.7;
    vec2 gridUV = abs(frac(uv) * 2.0 - 1.0);
    gridUV =  1.0 - gridUV;
    vec2 grid2 = smoothstep(drawWidth + lineAA, drawWidth - lineAA, gridUV);
    grid2 *= saturate(lineWidth / drawWidth);
    grid2 = lerp(grid2, W, saturate(uvDeriv * 2.0 - 1.0));
    return lerp(grid2.x, 1.0, grid2.y);
}

shader vec4 PS_UnconnectedNeon(posTexVertexOutput IN) : SV_TARGET
{
	vec3 view = normalize(TexCoordsToView(IN.texCoords).xyz);
	vec4 res=vec4(0,0,0,0.5);
	// flat surface at 0:
	float h=viewPosition.z;
	if(view.z<-0.001f)
	{
		float distance=h/-view.z;
		vec3 targetPosition=viewPosition+distance*view;
		vec2 fr=frac(targetPosition.xy);
		fr-=vec2(0.5,0.5);
		vec2 ln=abs(fr);
		float m=min(ln.x,ln.y);
		vec2 e=exp(-50.0*ln);
		float br=saturate(step(m,0.02)+(e.x+e.y));
		vec3 dir=normalize(vec3(targetPosition.xy,0.0));
		vec3 clr=dir+vec3(.5,.5,.5);
		float lineWidth=0.01;
		float grid=PristineGrid(targetPosition.xy,lineWidth);
		res.rgb=lerp(res.rgb,clr,grid*exp(-.03*distance));
	}
	if(view.z>0)
	{
		res.b+=0.2*exp(-10.0*view.z);
		res.rb+=0.4*exp(-50.0*view.z);

		float azimuth	=atan2(view.x,view.y);
		float a			=30.0*(1.0+azimuth/2.0/3.1415926);
		float rnd1		=PcgRand(uint(a));
		float rnd2		=PcgRand((uint(a)+1)%30);
		float a1		=a+0.2*rnd1;
		float tooth1	=2.0*min(frac(a1),1.0-frac(a1))*rnd1;
		float a2		=a+1.0+0.2*rnd2;
		float tooth2	=2.0*min(frac(a2),1.0-frac(a2))*rnd2;
		float tooth		=max(tooth1,tooth2);
		float Z			=0.02*tooth;
		if(view.z<Z)
			res.rgb*=0;
	}
	return res;
}

shader vec4 PS_UnconnectedWhite(posTexVertexOutput IN) : SV_TARGET
{
	vec3 view = normalize(TexCoordsToView(IN.texCoords).xyz);
	// framenumber to phase time.
	vec4 res=vec4(0.9,0.9,0.9,0.5);
	// flat surface at 0:
	float h=viewPosition.z;
	if (view.z <=0)
	{
		res.rgb=lerp(res.rgb,res.rgb*0.7,exp(5.0*view.z));
	}
	if(view.z<-0.01f)
	{
		float distance=h/-view.z;
		vec3 targetPosition=viewPosition+distance*view;
		float phase_length=length(targetPosition.xy);
		float phase_time=time_seconds/1.0;
		float cos_time=cos(phase_time*3.1415926536*2.0);
		float pulse=saturate(cos_time-0.9);
		float cosine=cos(phase_length*3.1415926536*2.0);
		float ring=1.0/(1.0-0.9+pulse)*saturate(cosine-0.9+pulse);
		float lineWidth=0.01;//*(1.0+5.0*ring);
		vec3 clr=view*vec3(.5,.5,.5);//+ring*vec3(5.0,5.0,5.0);
		float grid=PristineGrid(targetPosition.xy,lineWidth);
		//grid=max(grid,0.2*ring*exp(-.3*distance));
		res.rgb=lerp(res.rgb,res.rgb*clr,grid*exp(-.03*distance));
		res.rgb+=0.2*ring*exp(-.3*distance)*vec3(1.0,1.0,1.0);
	}
	if(view.z>0)
	{
		res.rgb=lerp(res.rgb,res.rgb*0.4,exp(-10.0*view.z));
		res.rgb=lerp(res.rgb,res.rgb*0.7,exp(-50.0*view.z));
	}
	//res.r=frac(cosine);
	return res;
}
shader vec4 PS_UnconnectedNeon_MV(posTexVertexOutput IN, uint viewID : SV_ViewID) : SV_TARGET
{
	vec3 _viewPosition = stereoViewPosition[viewID].xyz;
	vec3 view = normalize(TexCoordsToView(IN.texCoords, viewID).xyz);
	vec4 res = vec4(0, 0, 0, 1.0);
	// flat surface at 0:
	float h = _viewPosition.z;
	if (view.z < -0.1f)
	{
		float distance = h / -view.z;
		vec3 targetPosition = _viewPosition + distance * view;
		vec2 fr = frac(targetPosition.xy);
		fr -= vec2(0.5, 0.5);
		vec2 ln = abs(fr);
		float m = min(ln.x, ln.y);
		vec2 e = exp(-50.0 * ln);
		float br = saturate(step(m, 0.02) + (e.x + e.y));
		//vec3(0.4f,0.8f,0.9f)*
		vec3 clr = view + vec3(.5, .5, .5);
		float lineWidth=0.01;
		float grid=PristineGrid(targetPosition.xy,lineWidth);
		res.rgb=lerp(res.rgb,res.rgb*clr,grid*exp(-.03*distance));
	}
	if (view.z > 0)
	{
		res.b += 0.2 * exp(-10.0 * view.z);
		res.rb += 0.4 * exp(-50.0 * view.z);
	}
	return res;
}
shader vec4 PS_UnconnectedWhite_MV(posTexVertexOutput IN, uint viewID : SV_ViewID) : SV_TARGET
{
	vec3 _viewPosition = stereoViewPosition[viewID].xyz;
	vec3 view = normalize(TexCoordsToView(IN.texCoords, viewID).xyz);
	vec4 res = vec4(0.9, 0.9, 0.9, 1.0);
	// flat surface at 0:
	float h = viewPosition.z;
	if (view.z < -0.1f)
	{
		float distance = h / -view.z;
		vec3 targetPosition = viewPosition + distance * view;
		vec2 fr = frac(targetPosition.xy);
		fr -= vec2(0.5, 0.5);
		vec2 ln = abs(fr);
		float m = min(ln.x, ln.y);
		vec2 e = exp(-50.0 * ln);
		float br = saturate(step(m, 0.02) + (e.x + e.y));
		//vec3(0.4f,0.8f,0.9f)*
		vec3 clr = view * vec3(.5, .5, .5);
		res.rgb = lerp(res.rgb, res.rgb * clr, br * exp(-.3 * distance));
	//res.r=distance;
	}
	if (view.z > 0)
	{
		res.rgb = lerp(res.rgb, res.rgb * 0.2, exp(-10.0 * view.z));
		res.rgb = lerp(res.rgb, res.rgb * 0.4, exp(-50.0 * view.z));
	}
	return res;
}


shader vec4 PS_ShowTexture(posTexVertexOutput IN) : SV_TARGET
{
	vec4 lookup = plainTexture.SampleLevel(wrapSamplerState, IN.texCoords, 0);
	return lookup;
}

[numthreads(16, 16, 1)]
shader void CS_Recompose(uint3 g : SV_GroupID, uint3 t : SV_GroupThreadID)
{
	uint3 ThreadID = uint3(g.xy * 16 + t.xy,g.z);
	if (ThreadID.x >= targetSize.x || ThreadID.y >= targetSize.y)
		return;
	uint InputW, InputH;
	plainTexture.GetDimensions(InputW, InputH);
	uint OutputW, OutputH, OutputD;
	RWTextureTargetArray.GetDimensions(OutputW, OutputH, OutputD);
	int3 pos = int3(ThreadID);
	int2 FaceOffsets[] = { {0,0},{1,0},{2,0},{0,1},{1,1},{2,1} };
	vec4 SceneColor = plainTexture.Load(int3(pos.xy+sourceOffset+ OutputW*FaceOffsets[ThreadID.z],0));
	SceneColor.rgb *= SceneColor.rgb;
	RWTextureTargetArray[pos] = SceneColor;
}

groupshared uint accumulate_position[32];
// From the encoded binary at bottom-right
[numthreads(32, 1, 1)]
shader void CS_ExtractTagDataID(uint3 g : SV_GroupID, uint3 t : SV_GroupThreadID)
{
	uint2 ThreadID	= uint2(g.xy * 32 + t.xy);
	uint2 pos		= sourceOffset+4*ThreadID.xy;
	uint2 pos_x		= pos +uint2(2,2);
	// The offset is to the X component. The thread index gives us the bit mask.
	vec4 lookupX	= plainTexture.Load(int3(pos_x.xy, 0));
	// Convert the green component to a 0 or 1 uint. shift to get the binary.
	int bitX		= int(lookupX.g+0.5) << int(ThreadID.x);
	accumulate_position[ThreadID.x] = uint(bitX);
	GroupMemoryBarrierWithGroupSync();
	// Now join all the bits together.
	if(ThreadID.x==0)
	{
		uint all_bits = 0;
		for(int i=0;i<32;i++)
		{
			all_bits |= accumulate_position[i];
		}
		// use w for sanity check
		RWTagDataIDBuffer[0]= uint4(all_bits, 0, 0, 110);
	}
}

[numthreads(16, 16, 1)]
shader void CS_RecomposeWithDepthAlpha(uint3 g : SV_GroupID, uint3 t : SV_GroupThreadID)
{
	uint3 ThreadID = uint3(g.xy * 16 + t.xy, g.z);
	vec3 DepthMask[4];
	DepthMask[0] = vec3(1.0, 0.0, 0.0); //0,0);
	DepthMask[1] = vec3(0.0, 1.0, 0.0); //1,0);
	DepthMask[2] = vec3(0.0, 0.0, 1.0); //0,1);
	DepthMask[3] = vec3(0.0, 0.5, 0.5); //1,1);
	uint InputW, InputH;
	plainTexture.GetDimensions(InputW, InputH);
	uint OutputW, OutputH, OutputD;
	RWTextureTargetArray.GetDimensions(OutputW, OutputH, OutputD);
	int3 pos			= int3(ThreadID);
	int2 FaceOffsets[]	= { {0,0},{1,0},{2,0},{0,1},{1,1},{2,1} };
	int3 loadPos		= int3(pos.xy + OutputW * FaceOffsets[ThreadID.z], 0);
	vec4 SceneColor		= plainTexture.Load(int3(loadPos),0);

	int2 loadDepthPos	= loadPos.xy / 2;
	int2 offsetToPos	= pos.xy % 2;// -loadDepthPos * 2;
	loadDepthPos		+= int2(0, OutputW) * 2;	// underneath the main cube in the video texture.
	vec3 dMask			= DepthMask[offsetToPos.x];// +2 * offsetToPos.y ];
	vec3 lookupDepth	= plainTexture.Load(int3(loadDepthPos, 0)).rgb;

	float d = dot(lookupDepth, dMask);
	// RGB values must be squared here because the server used their square root to improve colour quantization in the video encoder. 
	SceneColor.rgb *= SceneColor.rgb;
	SceneColor.a = d;
	RWTextureTargetArray[pos] = SceneColor; // vec4(SceneColor.rgba);
}

[numthreads(16, 16, 1)]
shader void CS_RecomposePerspective(uint3 g : SV_GroupID, uint3 t : SV_GroupThreadID)
{
	int3 pos = int3(g.xy * 16 + t.xy, 0);
	uint InputW, InputH;
	plainTexture.GetDimensions(InputW, InputH);
	vec4 SceneColor = plainTexture.Load(pos);
	// RGB values are squared here because the server used their square root to improve colour quantization in the video encoder. 
	SceneColor.rgb *= SceneColor.rgb;
	float alpha = SceneColor.a;
	RWTextureTargetArray[pos] = SceneColor;//vec4(alpha, alpha, alpha, 1.0);
}

[numthreads(16, 16, 1)]
shader void CS_RecomposePerspectiveWithDepthAlpha(uint3 g : SV_GroupID, uint3 t : SV_GroupThreadID)
{
	int3 pos = int3(g.xy * 16 + t.xy, 0);
	vec3 DepthMask[4];
	DepthMask[0] = vec3(1.0, 0.0, 0.0); //0,0);
	DepthMask[1] = vec3(0.0, 1.0, 0.0); //1,0);
	DepthMask[2] = vec3(0.0, 0.0, 1.0); //0,1);
	DepthMask[3] = vec3(0.0, 0.5, 0.5); //1,1);

	uint OutputW, OutputH, OutputD;
	RWTextureTargetArray.GetDimensions(OutputW, OutputH, OutputD);
	vec4 SceneColor = plainTexture.Load(pos);

	int2 depthPos	    = int2(0, OutputH) + (pos.xy / 2);
	int2 offsetToPos	= pos.xy % 2;
	vec3 dMask			= DepthMask[offsetToPos.x];
	vec3 lookupDepth	= plainTexture.Load(int3(depthPos, 0)).rgb;

	float d = dot(lookupDepth, dMask);
	SceneColor.rgb *= SceneColor.rgb;
	SceneColor.a = d;
	RWTextureTargetArray[pos] = SceneColor;
}

[numthreads(16, 16, 1)]
shader void CS_Test(uint3 ThreadID : SV_DispatchThreadID)
{
	vec4 sampleColour = plainTexture.SampleLevel(wwcNearestSamplerState, vec2(ThreadID.xy) / 8.0, 0).rgba;
	vec4 texelFetchColour = plainTexture.Load(int3((ThreadID.xy / 4) % int2(2, 2), 0));
	sampleColour.rgb += vec3(0.1, 0.1, 0.1);
	RWTextureTargetArray[ThreadID] = 0.5 * (texelFetchColour + sampleColour); // vec4(SceneColor.rgba);
}

[numthreads(16, 16, 1)]
shader void CS_Test_Face_Colour(uint3 ThreadID : SV_DispatchThreadID)
{
	vec4 colour = vec4(0.0, 0.0, 0.0, 1.0);
	switch (ThreadID.z)
	{
		default:
		case 0:
			colour = vec4(1.0, 0.0, 0.0, 1.0);
			break;
		case 1:
			colour = vec4(0.0, 1.0, 1.0, 1.0);
			break;
		case 2:
			colour = vec4(0.0, 1.0, 0.0, 1.0);
			break;
		case 3:
			colour = vec4(1.0, 0.0, 1.0, 1.0);
			break;
		case 4:
			colour = vec4(0.0, 0.0, 1.0, 1.0);
			break;
		case 5:
			colour = vec4(1.0, 1.0, 0.0, 1.0);
			break;
	}
	
	RWTextureTargetArray[ThreadID] = 0.25 * colour;
}

VertexShader vs = CompileShader(vs_6_0, VS_SimpleFullscreen());

technique normal_view
{
	pass p0
	{
		SetRasterizerState(RenderNoCull);
		SetDepthStencilState(DisableDepth, 0);
		SetBlendState(DontBlend,vec4(0.0, 0.0, 0.0, 0.0), 0xFFFFFFFF);
		SetGeometryShader(NULL);
		SetVertexShader(vs);
		SetPixelShader(CompileShader(ps_6_0, PS_NormalView()));
	}
}

technique show_texture
{
	pass p0
	{
		SetRasterizerState( RenderNoCull );
		SetDepthStencilState( DisableDepth, 0 );
		SetBlendState(DontBlend,vec4( 0.0, 0.0, 0.0, 0.0), 0xFFFFFFFF );
		SetGeometryShader(NULL);
		SetVertexShader(vs);
		SetPixelShader(CompileShader(ps_6_0, PS_ShowTexture()));
	}
}
technique far_cubemap
{
	pass multiview
	{
		SetRasterizerState(RenderNoCull);
		SetDepthStencilState(DisableDepth, 0);
		SetBlendState(DontBlend, vec4(0.0, 0.0, 0.0, 0.0), 0xFFFFFFFF);
		SetGeometryShader(NULL);
		SetVertexShader(vs);
		SetPixelShader(CompileShader(ps_6_1, PS_FarCubemap_MV()));
	}
	pass singleview
	{
		SetRasterizerState(RenderNoCull);
		SetDepthStencilState(DisableDepth, 0);
		SetBlendState(DontBlend, vec4(0.0, 0.0, 0.0, 0.0), 0xFFFFFFFF);
		SetGeometryShader(NULL);
		SetVertexShader(vs);
		SetPixelShader(CompileShader(ps_6_0, PS_FarCubemap()));
	}
}
technique use_cubemap
{
	pass multiview
	{
		SetRasterizerState( RenderNoCull );
		SetDepthStencilState( DisableDepth, 0 );
		SetBlendState(DontBlend,vec4( 0.0, 0.0, 0.0, 0.0), 0xFFFFFFFF );
		SetGeometryShader(NULL);
		SetVertexShader(vs);
		SetPixelShader(CompileShader(ps_6_1, PS_UseCubemap_MV()));
	}
	pass singleview
	{
		SetRasterizerState( RenderNoCull );
		SetDepthStencilState( DisableDepth, 0 );
		SetBlendState(DontBlend,vec4( 0.0, 0.0, 0.0, 0.0), 0xFFFFFFFF );
		SetGeometryShader(NULL);
		SetVertexShader(vs);
		SetPixelShader(CompileShader(ps_6_0, PS_UseCubemap()));
	}
}
technique use_perspective
{
	pass multiview
	{
		SetRasterizerState( RenderNoCull );
		SetDepthStencilState( DisableDepth, 0 );
		SetBlendState(DontBlend,vec4( 0.0, 0.0, 0.0, 0.0), 0xFFFFFFFF );
		SetGeometryShader(NULL);
		SetVertexShader(vs);
		SetPixelShader(CompileShader(ps_6_1, PS_UsePerspective_MV()));
	}
	pass singleview
	{
		SetRasterizerState(RenderNoCull);
		SetDepthStencilState(DisableDepth, 0);
		SetBlendState(DontBlend, vec4(0.0, 0.0, 0.0, 0.0), 0xFFFFFFFF);
		SetGeometryShader(NULL);
		SetVertexShader(vs);
		SetPixelShader(CompileShader(ps_6_0, PS_UsePerspective()));
	}
}
technique far_perspective
{
	pass multiview
	{
		SetRasterizerState(RenderNoCull);
		SetDepthStencilState(DisableDepth, 0);
		SetBlendState(DontBlend, vec4(0.0, 0.0, 0.0, 0.0), 0xFFFFFFFF);
		SetGeometryShader(NULL);
		SetVertexShader(vs);
		SetPixelShader(CompileShader(ps_6_1, PS_FarPerspective_MV()));
	}
	pass singleview
	{
		SetRasterizerState(RenderNoCull);
		SetDepthStencilState(DisableDepth, 0);
		SetBlendState(DontBlend, vec4(0.0, 0.0, 0.0, 0.0), 0xFFFFFFFF);
		SetGeometryShader(NULL);
		SetVertexShader(vs);
		SetPixelShader(CompileShader(ps_6_0, PS_FarPerspective()));
	}
}
technique unconnected
{
	pass white_multiview
	{
		SetRasterizerState( RenderNoCull );
		SetDepthStencilState( DisableDepth, 0 );
		SetBlendState(DontBlend,vec4( 0.0, 0.0, 0.0, 0.0), 0xFFFFFFFF );
		SetGeometryShader(NULL);
		SetVertexShader(vs);
		SetPixelShader(CompileShader(ps_6_1, PS_UnconnectedWhite_MV()));
	}
	pass neon_multiview
	{
		SetRasterizerState( RenderNoCull );
		SetDepthStencilState( DisableDepth, 0 );
		SetBlendState(DontBlend,vec4( 0.0, 0.0, 0.0, 0.0), 0xFFFFFFFF );
		SetGeometryShader(NULL);
		SetVertexShader(vs);
		SetPixelShader(CompileShader(ps_6_1, PS_UnconnectedNeon_MV()));
	}
	pass white
	{
		SetRasterizerState(RenderNoCull);
		SetDepthStencilState(DisableDepth, 0);
		SetBlendState(DontBlend, vec4(0.0, 0.0, 0.0, 0.0), 0xFFFFFFFF);
		SetGeometryShader(NULL);
		SetVertexShader(vs);
		SetPixelShader(CompileShader(ps_6_0, PS_UnconnectedWhite()));
	}
	pass neon
	{
		SetRasterizerState(RenderNoCull);
		SetDepthStencilState(DisableDepth, 0);
		SetBlendState(DontBlend, vec4(0.0, 0.0, 0.0, 0.0), 0xFFFFFFFF);
		SetGeometryShader(NULL);
		SetVertexShader(vs);
		SetPixelShader(CompileShader(ps_6_0, PS_UnconnectedNeon()));
	}
}

technique extract_tag_data_id 
{
	pass p0
	{
		SetComputeShader(CompileShader(cs_6_0, CS_ExtractTagDataID()));
	}
}

technique recompose
{
	pass p0
	{
		SetComputeShader(CompileShader(cs_6_0, CS_Recompose()));
	}
}
technique recompose_with_depth_alpha
{
	pass p0
	{
		SetComputeShader(CompileShader(cs_6_0, CS_RecomposeWithDepthAlpha()));
	}

}
technique recompose_perspective
{
	pass p0
	{
		SetComputeShader(CompileShader(cs_6_0, CS_RecomposePerspective()));
	}
}
technique recompose_perspective_with_depth_alpha
{
	pass p0
	{
		SetComputeShader(CompileShader(cs_6_0, CS_RecomposePerspectiveWithDepthAlpha()));
	}
}

technique test
{
	pass test
	{
		SetComputeShader(CompileShader(cs_6_0, CS_Test()));
	}
	pass test_face_colour
	{
		SetComputeShader(CompileShader(cs_6_0, CS_Test_Face_Colour()));
	}
}